spring:
  transaction:
    default-timeout: 2
  application:
    name: test-demo
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      url: jdbc:mysql://121.196.62.153:3306/data_platform?allowMultiQueries=true&useUnicode=true&characterEncoding=UTF-8&useSSL=false
      username: root
      password: root
      driverClassName: com.mysql.jdbc.Driver
      initial-size: 10
      max-active: 100
      min-idle: 10
      max-wait: 60000
      pool-prepared-statements: true
      max-pool-prepared-statement-per-connection-size: 20
      time-between-eviction-runs-millis: 60000
      min-evictable-idle-time-millis: 300000
      validation-query: SELECT 1 FROM DUAL
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      stat-view-servlet:
        enabled: true
        url-pattern: /druid/*
      filter:
        stat:
          log-slow-sql: true
          slow-sql-millis: 1000
          merge-sql: true
        wall:
          config:
            multi-statement-allow: true
        log4j:
          connection-log-enabled: true
      useGlobalDataSourceStat: true
  data:
    elasticsearch:
      cluster-nodes: 172.21.72.161
      cluster-port: 9200
      username: elasticsearch
      password: 123456

  redis:
    database: 0
    host: 127.0.0.1
    port: 6379
    password:       # 密码（默认为空） # 连接超时时长（毫秒）
    timeout: 15000ms
    jedis:
      pool:
        max-active: 200  # 连接池最大连接数（使用负值表示没有限制）
        max-wait: -1ms      # 连接池最大阻塞等待时间（使用负值表示没有限制）
        max-idle: 10      # 连接池中的最大空闲连接
        min-idle: 5       # 连接池中的最小空闲连接



es:
  config:
    host: 172.21.72.161 #elasticSearch集群，多个地址以英文逗号隔开
    clusterName: elasticsearch
    transport:
      port: 9300
    response:
      size: 100

#  redis:
#    cluster:
#      #设置key的生存时间，当key过期时，它会被自动删除；
#      expire-seconds: 120
#      #设置命令的执行时间，如果超过这个时间，则报错;
#      command-timeout: 5000
#      #设置redis集群的节点信息，其中namenode为域名解析，通过解析域名来获取相应的地址;
#      nodes: namenode22:6379,datanode23:6379,datanode24:6379,datanode25:6379,datanode26:6379,datanode27:6379


#  kafka:
#    bootstrap-servers: 127.0.0.1:9092
#    #bootstrap-servers: 172.21.72.161:9096
#    #生产者的配置，大部分可以使用默认的，这里列出几个比较重要的属性
#    producer:
#      #每批次发送消息的数量
#      batch-size: 16
#      #设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
#      retries: 0
#      #producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
#      buffer-memory: 33554432
#      #key序列化方式
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#
#
#    #消费者的配置
#    consumer:
#      #Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
#      auto-offset-reset: latest
#      #是否开启自动提交
#      enable-auto-commit: true
#      #自动提交的时间间隔
#      auto-commit-interval: 100
#      #key的解码方式
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      #value的解码方式
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      #在/usr/local/etc/kafka/consumer.properties中有配置
#      group-id: ls
#      max-poll-records: 100


#安全验证
#  security:
#    user:
#      name: admin
#      password: 123456
#  cloud:
#    config:
#      uri: 127.0.0.1


#eureka:
#    instance:
#      hostname: test-demo
#      instance-id:
#      # 默认使用IP 地址进行显示
#      prefer-ip-address: true
#    client:
#    # 关闭eureka client
#      # enabled: false
#      # 注册自身到eureka服务器
#      #registerWithEureka: false
#      # 表示是否从eureka服务器获取注册信息
#      #fetchRegistry: false
#      # 客户端从Eureka Server集群里更新Eureka Server信息的频率
#      #eureka-service-url-poll-interval-seconds: 60
#      # 定义从注册中心获取注册服务的信息
#      #registry-fetch-interval-seconds: 5
#      # 设置eureka服务器所在的地址，查询服务和注册服务都需要依赖这个地址（不要使用service-Url）
#      serviceUrl:
#        defaultZone: http://${spring.security.user.name}:${spring.security.user.password}@127.0.0.1:8763/eureka/

kafka:
  enabled: true
  topic:
    num:
      partitions: 8

  thread:
    core:
      pool:
        size: 50
    maximum:
      pool:
        size: 100
    queue:
      capacity: 200

#  rabbitmq:
#    host: 10.0.98.46
#    port: 5672
#    username: admin
#    password: mon4498
#    # 支持发布确认
#    publisher-confirms: true
#    # 支持发布返回
#    publisher-returns: true
#    listener:
#      simple:
#        acknowledge-mode: manual
#        # 指定最小的消费者数量
#        concurrency: 5
#        # 指定最大的消费者数量
#        max-concurrency: 20
#        # 是否支持重试
#        retry:
#          enabled: true


